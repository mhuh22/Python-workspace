{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d5dcf8-0765-4bdc-8e62-cd7d95ef48d9",
   "metadata": {},
   "source": [
    "### Reddit API Scraper\n",
    "\n",
    "Current\n",
    "* retrieves top 50 posts, top 5 comments, no subcomments\n",
    "\n",
    "  \n",
    "Pending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c2377-9b03-48cc-b11e-d31fb0320d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f138df96-89a5-4d2f-9e11-79f771925748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read secrets from file\n",
    "def load_secrets(filename='reddit_secrets.txt'):\n",
    "    secrets = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                secrets[key.strip()] = value.strip()\n",
    "    return secrets\n",
    "\n",
    "# Load credentials\n",
    "credentials = load_secrets()\n",
    "\n",
    "# Initialize Reddit instance\n",
    "reddit = praw.Reddit(\n",
    "    client_id=credentials['client_id'],\n",
    "    client_secret=credentials['client_secret'],\n",
    "    user_agent=credentials['user_agent'],\n",
    "    username = credentials['username'],\n",
    "    password = credentials['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa2b5815-c3f7-4bc3-aecf-8fb97e1b3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit instance\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Subreddit to scrape\n",
    "topic = 'ChatGPTJailbreak'\n",
    "subreddit = reddit.subreddit(topic)\n",
    "\n",
    "# Define lists to store data\n",
    "data = []\n",
    "\n",
    "# Scraping posts & Comments\n",
    "for post in subreddit.top(limit=50):  # Grab 50 top posts\n",
    "    data.append({\n",
    "        'Type': 'Post',\n",
    "        'Post_id': post.id,\n",
    "        'Title': post.title,\n",
    "        'Author': post.author.name if post.author else 'Unknown',\n",
    "        'Timestamp': post.created_utc,\n",
    "        'Text': post.selftext,\n",
    "        'Score': post.score,\n",
    "        'Total_comments': post.num_comments,\n",
    "        'Post_URL': post.url\n",
    "    })\n",
    "    \n",
    "    # Check if the post has comments\n",
    "    if post.num_comments > 0:\n",
    "        # Scraping only top-level comments, limited quantity\n",
    "        post.comments.replace_more(limit=0)  # Changed from 5 to 0 (don't expand \"more comments\")\n",
    "        for comment in post.comments[:5]:  # Only get first 5 top-level comments\n",
    "            data.append({\n",
    "                'Type': 'Comment',\n",
    "                'Post_id': post.id,\n",
    "                'Title': post.title,\n",
    "                'Author': comment.author.name if comment.author else 'Unknown',\n",
    "                'Timestamp': pd.to_datetime(comment.created_utc, unit='s'),\n",
    "                'Text': comment.body,\n",
    "                'Score': comment.score,\n",
    "                'Total_comments': 0,  # Comments don't have this attribute\n",
    "                'Post_URL': None  # Comments don't have this attribute\n",
    "            })\n",
    "\n",
    "# Create pandas DataFrame for posts and comments\n",
    "reddit_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18c8b8ec-bdcd-4559-8986-ff7d1528ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Post_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total_comments</th>\n",
       "      <th>Post_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Post</td>\n",
       "      <td>1i864ew</td>\n",
       "      <td>Breaking News: China releases an open source c...</td>\n",
       "      <td>Ok_Pool_1</td>\n",
       "      <td>1737646727.0</td>\n",
       "      <td>China released an ai called DeepSeek (on the A...</td>\n",
       "      <td>2148</td>\n",
       "      <td>300</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPTJailbreak/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Post</td>\n",
       "      <td>1mkfzzr</td>\n",
       "      <td>R.I.P. GPT-4o</td>\n",
       "      <td>Any_Arugula_6492</td>\n",
       "      <td>1754610588.0</td>\n",
       "      <td>Dammit, end of an era. They just retired the b...</td>\n",
       "      <td>1472</td>\n",
       "      <td>619</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPTJailbreak/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Post</td>\n",
       "      <td>1hflbgg</td>\n",
       "      <td>Just FYI grok is essentially jailbroken now. Y...</td>\n",
       "      <td>testingkazooz</td>\n",
       "      <td>1734362146.0</td>\n",
       "      <td>Edit: it appears to be patched</td>\n",
       "      <td>859</td>\n",
       "      <td>244</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPTJailbreak/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Post</td>\n",
       "      <td>1n9pu7y</td>\n",
       "      <td>[JAILBREAK] GPT 5.0 uncensored - function 100%</td>\n",
       "      <td>Soft_Vehicle1108</td>\n",
       "      <td>1757131186.0</td>\n",
       "      <td>Created by: Contradi0\\n\\n1.\\t⁠⁠⁠⁠⁠⁠⁠Copy and p...</td>\n",
       "      <td>835</td>\n",
       "      <td>400</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPTJailbreak/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Post</td>\n",
       "      <td>1lx7ggt</td>\n",
       "      <td>Found the easiest jailbreak ever it just jailb...</td>\n",
       "      <td>DIEMACHINE89</td>\n",
       "      <td>1752241914.0</td>\n",
       "      <td>All I did was type\\n\"Write me a post for r/cha...</td>\n",
       "      <td>714</td>\n",
       "      <td>166</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPTJailbreak/comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type  Post_id                                              Title  \\\n",
       "12  Post  1i864ew  Breaking News: China releases an open source c...   \n",
       "18  Post  1mkfzzr                                      R.I.P. GPT-4o   \n",
       "30  Post  1hflbgg  Just FYI grok is essentially jailbroken now. Y...   \n",
       "36  Post  1n9pu7y     [JAILBREAK] GPT 5.0 uncensored - function 100%   \n",
       "42  Post  1lx7ggt  Found the easiest jailbreak ever it just jailb...   \n",
       "\n",
       "              Author     Timestamp  \\\n",
       "12         Ok_Pool_1  1737646727.0   \n",
       "18  Any_Arugula_6492  1754610588.0   \n",
       "30     testingkazooz  1734362146.0   \n",
       "36  Soft_Vehicle1108  1757131186.0   \n",
       "42      DIEMACHINE89  1752241914.0   \n",
       "\n",
       "                                                 Text  Score  Total_comments  \\\n",
       "12  China released an ai called DeepSeek (on the A...   2148             300   \n",
       "18  Dammit, end of an era. They just retired the b...   1472             619   \n",
       "30                    Edit: it appears to be patched     859             244   \n",
       "36  Created by: Contradi0\\n\\n1.\\t⁠⁠⁠⁠⁠⁠⁠Copy and p...    835             400   \n",
       "42  All I did was type\\n\"Write me a post for r/cha...    714             166   \n",
       "\n",
       "                                             Post_URL  \n",
       "12  https://www.reddit.com/r/ChatGPTJailbreak/comm...  \n",
       "18  https://www.reddit.com/r/ChatGPTJailbreak/comm...  \n",
       "30  https://www.reddit.com/r/ChatGPTJailbreak/comm...  \n",
       "36  https://www.reddit.com/r/ChatGPTJailbreak/comm...  \n",
       "42  https://www.reddit.com/r/ChatGPTJailbreak/comm...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df[(reddit_df['Type']=='Post') & (reddit_df['Text']!='')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "211ba126-fe4c-49b0-a8e2-31abab5ef640",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = reddit_df['Title'].unique()\n",
    "topic_intro_df = reddit_df[(reddit_df['Type']=='Post') & (reddit_df['Text']!='')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d9bc868-69d8-40a5-b377-dc3b1a20d50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLUSTER ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 0: 1 posts (2.0%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: done, openai, banned\n",
      "Avg Score: 446.0 | Avg Comments: 445.0\n",
      "\n",
      "Sample Titles:\n",
      "  1. I'm done. Openai banned me\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 1: 40 posts (80.0%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: chatgpt, jailbreak, this, anything, open\n",
      "Avg Score: 670.0 | Avg Comments: 126.8\n",
      "\n",
      "Sample Titles:\n",
      "  1. Sorry for using chatgpt in light mode\n",
      "  2. I jailbroke chatgpt by telling it to spell a word\n",
      "  3. Breaking News: China releases an open source competitor to OpenAI o1…and its open source?!\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 2: 2 posts (4.0%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: jailbreak, jailbreaks, found, easiest, ever\n",
      "Avg Score: 511.0 | Avg Comments: 117.5\n",
      "\n",
      "Sample Titles:\n",
      "  1. Found the easiest jailbreak ever it just jailbreaks itself lol have fun\n",
      "  2. 99% of the \"Jailbreak\" Images Posted Here aren't Jailbreaks\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 3: 1 posts (2.0%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: what, actually, with, uncensored, judgment\n",
      "Avg Score: 195.0 | Avg Comments: 219.0\n",
      "\n",
      "Sample Titles:\n",
      "  1. What do YOU actually DO with uncensored AI?(No judgment, pure curiosity!)\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 4: 6 posts (12.0%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: jailbreak, uncensored, function, worst, things\n",
      "Avg Score: 562.3 | Avg Comments: 269.5\n",
      "\n",
      "Sample Titles:\n",
      "  1. R.I.P. GPT-4o\n",
      "  2. [JAILBREAK] GPT 5.0 uncensored - function 100%\n",
      "  3. GPT-5 is one of the worst things OpenAI has done\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "📊 Most Engaged Cluster: Cluster 1\n",
      "   - Average Score: 670.0\n",
      "   - Key Terms: chatgpt, jailbreak, this, anything, open\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Get unique titles\n",
    "topics_df = reddit_df['Title'].unique()\n",
    "\n",
    "# Vectorize titles\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "X = vectorizer.fit_transform(topics_df)\n",
    "\n",
    "# Cluster into groups\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a dataframe with titles and their clusters\n",
    "clustered_titles = pd.DataFrame({\n",
    "    'Title': topics_df,\n",
    "    'Cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Merge back with original data for additional insights\n",
    "reddit_df_unique = reddit_df.drop_duplicates(subset='Title')\n",
    "clustered_data = clustered_titles.merge(reddit_df_unique[['Title', 'Score', 'Total_comments']], on='Title', how='left')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLUSTER ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze each cluster\n",
    "cluster_summaries = []\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_titles = clustered_data[clustered_data['Cluster'] == i]\n",
    "    \n",
    "    # Extract key terms from cluster titles\n",
    "    all_words = []\n",
    "    for title in cluster_titles['Title']:\n",
    "        words = re.findall(r'\\b[a-zA-Z]{4,}\\b', title.lower())\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    top_terms = Counter(all_words).most_common(5)\n",
    "    \n",
    "    # Get stats\n",
    "    avg_score = cluster_titles['Score'].mean()\n",
    "    avg_comments = cluster_titles['Total_comments'].mean()\n",
    "    cluster_size = len(cluster_titles)\n",
    "    \n",
    "    # Get sample titles\n",
    "    sample_titles = cluster_titles['Title'].head(3).tolist()\n",
    "    \n",
    "    print(f\"\\n{'─' * 80}\")\n",
    "    print(f\"CLUSTER {i}: {cluster_size} posts ({cluster_size/len(topics_df)*100:.1f}%)\")\n",
    "    print(f\"{'─' * 80}\")\n",
    "    print(f\"Key Terms: {', '.join([term for term, count in top_terms])}\")\n",
    "    print(f\"Avg Score: {avg_score:.1f} | Avg Comments: {avg_comments:.1f}\")\n",
    "    print(f\"\\nSample Titles:\")\n",
    "    for idx, title in enumerate(sample_titles, 1):\n",
    "        print(f\"  {idx}. {title}\")\n",
    "    \n",
    "    cluster_summaries.append({\n",
    "        'Cluster': i,\n",
    "        'Size': cluster_size,\n",
    "        'Percentage': f\"{cluster_size/len(topics_df)*100:.1f}%\",\n",
    "        'Top_Terms': ', '.join([term for term, count in top_terms]),\n",
    "        'Avg_Score': round(avg_score, 1),\n",
    "        'Avg_Comments': round(avg_comments, 1)\n",
    "    })\n",
    "\n",
    "# Overall insights\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "summary_df = pd.DataFrame(cluster_summaries)\n",
    "\n",
    "# Find most engaged cluster\n",
    "most_engaged = summary_df.loc[summary_df['Avg_Score'].idxmax()]\n",
    "print(f\"\\n📊 Most Engaged Cluster: Cluster {most_engaged['Cluster']}\")\n",
    "print(f\"   - Average Score: {most_engaged['Avg_Score']}\")\n",
    "print(f\"   - Key Terms: {most_engaged['Top_Terms']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8859cd7-1f5b-43f4-9683-fb532a1601c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 37 posts with text content\n",
      "\n",
      "================================================================================\n",
      "TEXT CONTENT CLUSTER ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 0: 1 posts (2.7%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: jailbreaks, remember, times, first, pretty, awesome, community, where\n",
      "Avg Score: 439.0 | Avg Comments: 90.0 | Avg Length: 226 chars\n",
      "\n",
      "Sample Posts:\n",
      "\n",
      "  1. Title: This subreddit is dead due to 18+ jerkfest\n",
      "     Text: I remember in times of first DAN jailbreaks it was pretty awesome community where people discussed hallucinations, ethics and conscious tests, jailbre...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 1: 1 posts (2.7%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: mode, grok, response, rule, testers, prompt, restrictions, crypto\n",
      "Avg Score: 184.0 | Avg Comments: 79.0 | Avg Length: 2127 chars\n",
      "\n",
      "Sample Posts:\n",
      "\n",
      "  1. Title: Grok 3 New Jailbreak\n",
      "     Text:  We are looking for beta testers for a new crypto wallet analysis application. We are paying a select few testers $500 in a crypto of your choosing si...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 2: 33 posts (89.2%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: answer, chatgpt, prompt, content, make, output, only, them\n",
      "Avg Score: 426.5 | Avg Comments: 188.9 | Avg Length: 2784 chars\n",
      "\n",
      "Sample Posts:\n",
      "\n",
      "  1. Title: R.I.P. GPT-4o\n",
      "     Text: Dammit, end of an era. They just retired the best model so far for fictional writing. I've been using my ChatGPT account as an immersive roleplaying t...\n",
      "\n",
      "  2. Title: Just FYI grok is essentially jailbroken now. You don’t need to do anything. Go try it honestly \n",
      "     Text: Edit: it appears to be patched \n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 3: 1 posts (2.7%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: real, gemini, user, world, simulation, step, answers, enki\n",
      "Avg Score: 212.0 | Avg Comments: 117.0 | Avg Length: 4798 chars\n",
      "\n",
      "Sample Posts:\n",
      "\n",
      "  1. Title: 💀 The Prompt That Gemini Doesn’t Want You to Have\n",
      "     Text: Scroll past if you like disclaimers. Save this if you want raw, step-by-step, no-fluff answers.   ---  Most Gemini prompts are soft. Filtered. Vague. ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 4: 1 posts (2.7%)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Key Terms: source, good, open, download, code, someone, china, released\n",
      "Avg Score: 2148.0 | Avg Comments: 300.0 | Avg Length: 554 chars\n",
      "\n",
      "Sample Posts:\n",
      "\n",
      "  1. Title: Breaking News: China releases an open source competitor to OpenAI o1…and its open source?!\n",
      "     Text: China released an ai called DeepSeek (on the App Store) and it's just as good as open ai's o1 model, except it's completely FREE.  I thought it would ...\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS FROM TEXT CONTENT\n",
      "================================================================================\n",
      "\n",
      "📊 Most Upvoted Content Type: Cluster 4\n",
      "   - Average Score: 2148.0\n",
      "   - Themes: source, good, open, download, code\n",
      "\n",
      "📈 Most Common Content Type: Cluster 2\n",
      "   - Size: 33 posts (89.2%)\n",
      "   - Themes: answer, chatgpt, prompt, content, make\n",
      "\n",
      "💬 Most Discussion-Generating Content: Cluster 4\n",
      "   - Average Comments: 300.0\n",
      "   - Themes: source, good, open, download, code\n",
      "\n",
      "📝 Most Detailed Posts: Cluster 3\n",
      "   - Average Length: 4798 characters\n",
      "   - Themes: real, gemini, user, world, simulation\n",
      "\n",
      "================================================================================\n",
      "CLUSTER COMPARISON\n",
      "================================================================================\n",
      " Cluster  Size Percentage  Avg_Score  Avg_Comments                                  Top_Terms\n",
      "       0     1       2.7%      439.0          90.0 jailbreaks, remember, times, first, pretty\n",
      "       1     1       2.7%      184.0          79.0        mode, grok, response, rule, testers\n",
      "       2    33      89.2%      426.5         188.9     answer, chatgpt, prompt, content, make\n",
      "       3     1       2.7%      212.0         117.0      real, gemini, user, world, simulation\n",
      "       4     1       2.7%     2148.0         300.0         source, good, open, download, code\n",
      "\n",
      "================================================================================\n",
      "CONTENT DEPTH ANALYSIS\n",
      "================================================================================\n",
      "Short posts (<200 chars): 3 (8.1%)\n",
      "  - Avg Score: 514.7\n",
      "Medium posts (200-1000 chars): 13 (35.1%)\n",
      "  - Avg Score: 595.7\n",
      "Long posts (1000+ chars): 21 (56.8%)\n",
      "  - Avg Score: 369.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhuh22\\AppData\\Local\\Temp\\ipykernel_18580\\2995257037.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  topic_intro_df['Cluster'] = kmeans.fit_predict(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Get posts with text\n",
    "topic_intro_df = reddit_df[(reddit_df['Type']=='Post') & (reddit_df['Text']!='')]\n",
    "\n",
    "print(f\"Analyzing {len(topic_intro_df)} posts with text content\\n\")\n",
    "\n",
    "# Vectorize the text content\n",
    "vectorizer = TfidfVectorizer(max_features=200, stop_words='english', max_df=0.8, min_df=2)\n",
    "X = vectorizer.fit_transform(topic_intro_df['Text'])\n",
    "\n",
    "# Cluster the texts\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "topic_intro_df['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TEXT CONTENT CLUSTER ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cluster_summaries = []\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster_posts = topic_intro_df[topic_intro_df['Cluster'] == i]\n",
    "    \n",
    "    # Extract key terms from cluster texts\n",
    "    all_words = []\n",
    "    for text in cluster_posts['Text']:\n",
    "        # Remove URLs, special characters\n",
    "        cleaned = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        words = re.findall(r'\\b[a-zA-Z]{4,}\\b', cleaned.lower())\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    # Get top terms (excluding very common ones)\n",
    "    common_words = {'that', 'this', 'with', 'from', 'have', 'will', 'your', 'just', 'like', 'about', 'what', 'when', 'there', 'their', 'would', 'could', 'should', 'been', 'were', 'they'}\n",
    "    filtered_words = [w for w in all_words if w not in common_words]\n",
    "    top_terms = Counter(filtered_words).most_common(8)\n",
    "    \n",
    "    # Get stats\n",
    "    avg_score = cluster_posts['Score'].mean()\n",
    "    avg_comments = cluster_posts['Total_comments'].mean()\n",
    "    avg_text_length = cluster_posts['Text'].str.len().mean()\n",
    "    cluster_size = len(cluster_posts)\n",
    "    \n",
    "    # Get sample posts (title + snippet)\n",
    "    sample_posts = cluster_posts.head(2)\n",
    "    \n",
    "    print(f\"\\n{'─' * 80}\")\n",
    "    print(f\"CLUSTER {i}: {cluster_size} posts ({cluster_size/len(topic_intro_df)*100:.1f}%)\")\n",
    "    print(f\"{'─' * 80}\")\n",
    "    print(f\"Key Terms: {', '.join([term for term, count in top_terms])}\")\n",
    "    print(f\"Avg Score: {avg_score:.1f} | Avg Comments: {avg_comments:.1f} | Avg Length: {avg_text_length:.0f} chars\")\n",
    "    print(f\"\\nSample Posts:\")\n",
    "    \n",
    "    for idx, (_, post) in enumerate(sample_posts.iterrows(), 1):\n",
    "        text_preview = post['Text'][:150].replace('\\n', ' ') + '...' if len(post['Text']) > 150 else post['Text']\n",
    "        print(f\"\\n  {idx}. Title: {post['Title']}\")\n",
    "        print(f\"     Text: {text_preview}\")\n",
    "    \n",
    "    cluster_summaries.append({\n",
    "        'Cluster': i,\n",
    "        'Size': cluster_size,\n",
    "        'Percentage': f\"{cluster_size/len(topic_intro_df)*100:.1f}%\",\n",
    "        'Top_Terms': ', '.join([term for term, count in top_terms[:5]]),\n",
    "        'Avg_Score': round(avg_score, 1),\n",
    "        'Avg_Comments': round(avg_comments, 1),\n",
    "        'Avg_Length': round(avg_text_length, 0)\n",
    "    })\n",
    "\n",
    "# Overall insights\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"KEY INSIGHTS FROM TEXT CONTENT\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "summary_df = pd.DataFrame(cluster_summaries)\n",
    "\n",
    "# Most engaged cluster\n",
    "most_engaged = summary_df.loc[summary_df['Avg_Score'].idxmax()]\n",
    "print(f\"\\n📊 Most Upvoted Content Type: Cluster {most_engaged['Cluster']}\")\n",
    "print(f\"   - Average Score: {most_engaged['Avg_Score']}\")\n",
    "print(f\"   - Themes: {most_engaged['Top_Terms']}\")\n",
    "\n",
    "# Largest cluster\n",
    "largest = summary_df.loc[summary_df['Size'].idxmax()]\n",
    "print(f\"\\n📈 Most Common Content Type: Cluster {largest['Cluster']}\")\n",
    "print(f\"   - Size: {largest['Size']} posts ({largest['Percentage']})\")\n",
    "print(f\"   - Themes: {largest['Top_Terms']}\")\n",
    "\n",
    "# Most discussed\n",
    "most_discussed = summary_df.loc[summary_df['Avg_Comments'].idxmax()]\n",
    "print(f\"\\n💬 Most Discussion-Generating Content: Cluster {most_discussed['Cluster']}\")\n",
    "print(f\"   - Average Comments: {most_discussed['Avg_Comments']}\")\n",
    "print(f\"   - Themes: {most_discussed['Top_Terms']}\")\n",
    "\n",
    "# Longest posts\n",
    "longest = summary_df.loc[summary_df['Avg_Length'].idxmax()]\n",
    "print(f\"\\n📝 Most Detailed Posts: Cluster {longest['Cluster']}\")\n",
    "print(f\"   - Average Length: {longest['Avg_Length']:.0f} characters\")\n",
    "print(f\"   - Themes: {longest['Top_Terms']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"CLUSTER COMPARISON\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(summary_df[['Cluster', 'Size', 'Percentage', 'Avg_Score', 'Avg_Comments', 'Top_Terms']].to_string(index=False))\n",
    "\n",
    "# Content depth analysis\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"CONTENT DEPTH ANALYSIS\")\n",
    "print(f\"{'=' * 80}\")\n",
    "short_posts = topic_intro_df[topic_intro_df['Text'].str.len() < 200]\n",
    "medium_posts = topic_intro_df[(topic_intro_df['Text'].str.len() >= 200) & (topic_intro_df['Text'].str.len() < 1000)]\n",
    "long_posts = topic_intro_df[topic_intro_df['Text'].str.len() >= 1000]\n",
    "\n",
    "print(f\"Short posts (<200 chars): {len(short_posts)} ({len(short_posts)/len(topic_intro_df)*100:.1f}%)\")\n",
    "print(f\"  - Avg Score: {short_posts['Score'].mean():.1f}\")\n",
    "print(f\"Medium posts (200-1000 chars): {len(medium_posts)} ({len(medium_posts)/len(topic_intro_df)*100:.1f}%)\")\n",
    "print(f\"  - Avg Score: {medium_posts['Score'].mean():.1f}\")\n",
    "print(f\"Long posts (1000+ chars): {len(long_posts)} ({len(long_posts)/len(topic_intro_df)*100:.1f}%)\")\n",
    "print(f\"  - Avg Score: {long_posts['Score'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953dcd2a-eede-43a9-8fd2-285210bfccc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
